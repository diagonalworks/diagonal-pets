# Pandemic Response Modelling with Privacy Enhancing Technology: A Place-Centric Approach
## Diagonal Works Ltd, September 2022

<hello@diagonal.works>

## Abstract
We present an approach to federated learning for pandemic response based feature-engineering. We describe how features that aggregate and embed the information distributed across partitions can be computed in a privacy-preserving manner using a novel combination of well understood homomorphic encryption systems with a form of noise inspired by randomised response. These features can then be used with any machine learning approach; no explicit privacy-preservation techniques need to be added at the training stage, as the features themselves do not represent sensitive data.

Given the mission of our company, our approach emphasises features derived from the locations visited by an individual. Our approach can be seen, however, as a set of reusable parts from which other, non location-centric, feature generation protocols can be built.

## Background
Machine learning techniques are regularly used to model systems with mechanics that are difficult for humans to explicitly describe, learning instead from data describing the observed behaviour of a system. They can struggle, however, to learn behaviour from weak signals within that data. They can also fail to generalise, embedding specific observed events within the model. These two failure modes represent particular problems for pandemic response. In the early stages of a pandemic few individuals are infected, producing a fundamentally weak signal that may be difficult to learn from. Separately, data about the development of a pandemic is sensitive, comprising the medical and location history of individuals. Embedding such data within a model represents a risk to the privacy of an individual, as aspects of that data could potentially be extracted from the model.

Techniques exist to reduce the privacy risk of machine learning models trained on sensitive data. Noise can be deliberately introduced into a model, to mask the impact of an individual. Ideally, an attempt to discover data about an individual results only in noise, a concept mathematically defined as differential privacy. Separately, federated learning partitions training data into distinct subsets, and a single model is built by aggregating distinct models built from each subset. This approach to learning has benefits when, for example, legal or policy constraints prevent the combining of data to build a single model directly. Each of these techniques present a challenge to learning from weak signals. Achieving differential privacy generically, through the introduction of noise, necessarily obscures the weak signals inherent at the fringes of pandemic spread. Partitioning a single dataset risks smearing a weak signal across all partitions, rendering it undetectable with generic federated learning. A dataset partitioned geographically, for example, may make it difficult for federated learning techniques to discover patterns of interaction between people from different geographic partitions.

The introduction of noise to generically protect privacy establishes a flexible tradeoff between model accuracy and privacy. Currently, no deliberative process has been found that allows representatives of the public to arrive at an informed position on that tradeoff, despite it being [established][4] that transparency with, and the participation of, that public is crucial to maintaining the social licence necessary to work with sensitive data.

Homomorphic encryption is a cryptographic technique that allows computations to be performed on encrypted data, leaving the result of that computation encrypted. It can be used to build a system that preserves privacy by allowing a third party to work with sensitive data, without being able to access the data itself. Homomorphic encryption systems vary in the set of mathematical operations they permit, and their efficiency of operation. In general, systems with a level of performance and robustness currently useful for real world systems support a limited set of operations, whereas systems supporting the full range of mathematical operations can be difficult to use in practice. The [Paillier][1] homomorphic encryption system is an example of the former, allowing the addition of encrypted numbers, and the multiplication of an encrypted number with a plaintext number, with practical real-world performance. A number of robust, efficient, implementations of the system exist. The [THFE][2] homomorphic encryption system is an example of the latter, allowing reasonably efficient implementation of any operation, though currently with few production-standard implementations.

## Design

### High level approach
We emphasise feature engineering, computing a range of high-value features that preserve privacy by design. We mirror the traditional federated learning architecture, in which a single central server coordinates the action of a number of nodes, each node managing a partition of sensitive data. Rather than combining models, our central server computes features that aggregate the sensitive data from all nodes, distributing those features back to the nodes. Feature computation occurs in two phases: an aggregation phase, in which the central server computes aggregate metrics from the sensitive data in each node, and a distribution phase, in which nodes request the features for individual training examples, and the central server constructs them using its aggregate metrics. We use the Paillier homomorphic encryption system, with a key shared between nodes but unknown to the server, to compute aggregate metrics at the server without exposing it to the sensitive data forming the aggregate. Additionally, we inject a form of noise inspired by [randomised response][5] to prevent the server from using pattern recognition attacks on the attributes being aggregated. While injecting noise typically establishes a tradeoff between privacy and accuracy, we establish a tradeoff between computational cost and accuracy, and show that a robust, explainable level of protection is easy to provide.

Our approach emphasises the human curation of high value features usable by smaller models over a larger model with features closer to the underlying data. While counter to the current trend of increasingly large neural networks, the use of curated features makes explicit the flow of sensitive data. This explicitness ensures the approach is explainable, and keeps the privacy tradeoffs inherent given the domain at a concrete level that allows discussion by people impacted by the system, rather than restricting it to computer scientists through abstraction. The approach, nevertheless, permits the use of larger models for automated feature discovery, a potential area for future work.

Once features have been distributed to nodes, they can be used with any standard machine learning algorithm. No explicit privacy-preservation techniques need to be implemented, as the features themselves do not represent sensitive data. Federated learning techniques could be used to aggregate models trained at each node, although as our features aggregate data across nodes, the uplift in accuracy may not be worth the increase in implementation complexity if data partitions are reasonably balanced.

In the following section, we present a number of features, and a protocol for computing and distributing them. We focus on features related to the location history of individuals, as it both represents a particularly sensitive class of data about individuals, and is an important class of data for Diagonal as a company, given we specialise in urban geospatial analysis. The protocol can be seen as a framework, however, with the graph location co-visitation replaceable, for example,  with a graph of population interaction.

### Features from counting infected visits
#### Basic feature generation
Counting the total number of infected people at locations visited by an individual during their daily activity is an obvious feature for a model of infection risk. It relies on sensitive data, however, particularly the infection status of an individual, and their history of visited locations. Furthermore, components of the feature are likely to reside in different partitions of the data, as individuals in different partitions visit the same place. We describe a baseline protocol for computing such a feature in a privacy preserving manner below. Our baseline protocol computes a time-independent feature, which neither includes when infected individuals could have been encountered, nor for how long a potential encounter lasted, if they overlapped temporally at  all; we later describe how to extend the feature to include these aspects.
Let the central server be s, and the nodes managing sensitive data be n1, n2…nn.

1. One node, ni, generates the key pair necessary for the Paillier cryptosystem. The choice of node is arbitrary, and could simply be done by ordering the unique node identifiers inherent in any system, or having s make a random choice.
2. ni distributes the key pair to all other nodes. We assume all communication within the system occurs over a protocol guaranteeing authentication, confidentiality and integrity, for example, TLS with correctly managed server and client certificates.
3. Each node aggregates the count of infected individuals at each location into a set of pairs (li, ci), where li  is a unique identifier for a location consistent between nodes, and ci is the number of infected individuals at it. li is chosen such that s cannot deduce the physical location represented by the identifier. We use a numeric cellular location representation provided by the [S2 library][6], hashed with a seed shared between nodes but kept secret from the server, though many other approaches are possible. Each ci is then encrypted using the Paillier cryptosystem, and sent to s. The encryption operation is embarrassingly parallel.
4. s groups the counts from each node by li, computing a sum of each respective ci homomorphically. This operation is also embarrassingly parallel, reducing the latency impact of using homomorphic operations over conventional. We end the first phase with s holding a map from location identifiers to the encrypted total of the number of individuals at each location.
5. To form a training example, each ni sends a location history for an individual to the server of the form (l0, l1, l2…ln), where each lj represents a place visited by the individual. s responds by homomorphically summing the cj  for each lj and replying to ni, which decrypts the value to construct the feature.

#### Adding noise to disguise patterns within location visits
While the use of homomorphic encryption prevents s from learning the number of infected individuals at each location, and the use of opaque location identifiers prevents it from learning the physical locations visited by individuals, it can learn from patterns of location identifiers. Specifically, s can learn whether two individuals visited the same locations as lj  are shared in step 5. This  issue leaves data at s open to attack by combination with auxiliary data. We address this through the application of noise.

To protect the geographic distribution of locations between nodes, we simply have each node report counts for all known locations, many of which will be zero. As each reports a ni count for every lj, no distribution reconstruction is possible. Preventing s from establishing co-visit relationships between individuals is more involved. We use an approach inspired by randomised response, creating a “shadow” set of fake location identifiers, slj. Each slj is given an infection count of 0, and sent to s in step 3. The values of slj are chosen such that they neither collide with values of lj, nor have a distinct  distribution. We accomplish this requirement by deriving a slj for each lj by modifying unused bits of the location identifier prior to hashing. When the list of locations visited by an individual is formed in step 5, it’s augmented with an equal number of slj. As each slj is associated with a count of zero, feature computation isn’t impacted. From the perspective of s, each location identifier is as likely to be fake as it is to be true, frustrating attack to a workable level in an explainable manner. The level of protection can, if deemed necessary, be increased by increasing the ratio of fake locations to true locations. Rather than impacting accuracy, increasing noise affects only the resource requirements of the system.

To offer full protection, the selection of slj added to place visits needs to be such that the distribution of slj  co-occurrence mirrors those of lj in the true visit data. As an slj is deterministically formed from each lj, we accomplish this by merging the true lj for the individual under consideration with the slj generated from the true lj data from another, randomly selected, individual within the node. An alternate approach would be to use a Markov chain to generate realistic sequences of fake locations.

#### Mitigating malicious nodes
If malicious behaviour by a node falls within the threat model, then the exact counts of location visits should have noise applied to them to prevent the derivation of data about an individual through combination with auxiliary sources. A simple approach would be to have a node generate homomorphically encrypted Laplacian noise for each location, added at the server along with other partial counts. This is, however, vulnerable to a malicious node producing invalid noise without further modification to ensure noise integrity.

In general, a malicious node could attempt to learn data about an individual by repeatedly lying in step 5, and combining the results with auxiliary data. One mitigation approach would be to write a cryptographically immutable log of the actions of each node, use metrics summarising the progress of the protocol to detect potential lying, and verifying it by inspecting the log.

#### Implementation practicality
To estimate the real world resource requirements of feature generation, we make the following assumptions:
- 32 million possible places to be visited (from the simulated data for the UK)
- 50ns per homomorphic addition on a single modern core ([from literature][3])
- 10 nodes holding data partitions (from the technical brief)
- 512bit Paillier key size (reasonable protection in an honest-but-curious threat model)

Assuming key size dominates the Paillier ciphertext size, we assume 1024 bit (128 bytes) encrypted sums in a linear array of 64 million entries (half true, half fake), indexed by location identifier, totalling ~8Gb. Summing the 10 partitioned values for each of the 64 million entries at 50ns per sum would take ~32 seconds, before parallelisation. Both the memory and compute requirements are, therefore, trivally handled by a reasonable modern virtual machine, even as part of a system that computes a number of such features in succession.

#### Features embedding visit time and duration
Our baseline protocol generates a feature based on location co-visitation, without embedding the time or duration of a visit. The protocol can be expanded to include the time of a visit by repeating the protocol, with each iteration considering only visits within a given block of time within a given day. For example, the protocol could be rerun 28 times, generating features representing the number of potentially infected individuals encountered over the 6 hour blocks comprising the previous 7 days. Features embedding the duration of a visit could be generated similarly, by partitioning visits by their roughly quantized duration. Alternatively, longer visits could be emphasised by multiplying the count of infected individuals by the duration of a visit, implemented by repeated addition of the encrypted values.

#### Features embedding encounter probability
Our baseline protocol generates features that embed solely the number of visits by infected individuals to a given location, and not the total number of visits. It’s reasonable to assume features based on the ratio of infected visits to total visits could add predictive value. Assume a simple model of infection probability following visits to n locations is: 1 - Π(tj - ij)/tj for each location j from 0 to n, where tj is the total number of visits to location j, and ij the number of infected visits to location j.

Computation of this feature is beyond a basic application of the Paillier cryptosystem, which only supports the addition of encrypted numbers, or the multiplication of an encrypted number with a plaintext number. One implementation approach could be to use a slower homomorphic cryptosystem that supports both addition and multiplication. An alternate approach, implementable with the Paillier cryptosystem, would be possible if the values of tj were deemed less sensitive than ij. An encrypted ij and a plaintext tj could be computed at s, followed by the partial product (tj - ij)/tj homomorphically. These partial products, one for each location visited by the individual, could then be returned to the requesting node where the final product can be computed from the decrypted values using conventional arithmetic. While the order of the returned partial products could be shuffled, breaking the obvious mapping from location to probability, the potential for a node to deduce the modelled probability for a given location is obvious. Ultimately, a tradeoff in implementation choice would need to be made based on the effectiveness of the feature, the cost of a purely homomorphic encryption based implementation, and the social and legal context around the sensitivity of the aggregate values. We later describe an alternative practical solution based on the use of secure enclaves.

#### Features embedding location graph connectivity
Infection will spread more easily between two locations visited by a significant number of people in common than locations visited by few. Assume a weighted graph in which nodes represent locations, and the weight of an edge between nodes represents the number of individuals visiting both locations. Features that may aid model generalisation could be computed by taking the infection count and probability features described earlier, and augmenting them by either computing them for locations encountered on random walks, or limited breadth first traversal of the graph, from places visited by an individual. The graph itself could be computed by extending our basic protocol, aggregating counts for pairs of locations rather than individual locations. While the protocol changes are minor, the size of the resulting graph would push the limits of practicality for entirely in-memory representation on a single, modern virtual machine. One approach to render the implementation practical would be to elide infrequently visited locations, as these would necessarily provide little predictive power. The set of frequently visited locations could be estimated by each node based on their own visit data, or computed exactly if the number of total visits to a location was deemed shareable between nodes, using a protocol similar to our baseline.

#### Use of secure enclaves
Secure enclaves, or trusted execution environments, provide a hardware supported mechanism in which computation can take place with confidentiality and integrity guarantees covering both code and data. Generally these environments have hardware restrictions on resources usable within the enclave.

In step 3 of our baseline protocol, each node aggregates the count of infected individuals by location using conventional arithmetic, before aggregating them across nodes at the server homomorphically. The initial aggregation at the node improves efficiency by reducing the number of homomorphic operations. If we were willing to eschew this efficiency, and have all aggregation occur at the server homomorphically, all node operations would take place at the level of an individual. With this change, it would be possible to run the node-side part of the protocol entirely within a secure enclave, working with the data for a single individual at a time. Communication with the server could happen outside the enclave, once data had been homomorphically encrypted.

Running the node-side part of the protocol within a secure enclave would not only reduce the surface area of attack, but allow improvements to the efficiency and ease of the feature generation. With node-side code audited and signed before execution, and verified within the secure enclave, the risk of privacy attack within that code is mitigated. Trusting this code would remove the need to rely on homomorphic operations at the server in some cases, instead trusting the node to use conventional operations. For example, when computing features based on probabilities in the manner described earlier, we would neither need to rely on a cryptosystem supporting more than addition, nor expose total visit counts to the server, as the full probability could be computed within the secure enclave from the homophonically computed visit counts for each location provided by the server.

### Future work
We’ve described a baseline protocol for computing features predicting location based features for predicting an individual’s risk of infection, in a privacy preserving manner. We view these ideas as a set of reusable parts, from which the computation of many different features could be built. The standard feature engineering cycle involves brainstorming features, implementing them, and assessing their power within a model. An obvious source of future work is the repetition of this cycle.

An alternative source of future work is a widening of our definition of privacy. While differential privacy in machine learning is generally thought of as disguising the impact of any one individual on a model, we could instead consider the impact of any one location, or more usefully category of location. If infection was very strongly correlated with a particular category of location, but not others, one could imagine the confidence score output by a model being seen as a predictor for visiting such a location - itself a potentially sensitive property. Protecting against such inference, while recognising both the predisposition of particular demographics to infection, and likelihood of those same demographics to visit similar locations, would need careful interplay between the technical and social aspects of any solution.

[1]: https://dl.acm.org/doi/10.5555/1756123.1756146 "Public-Key Cryptosystems Based on Composite Degree Residuosity Classes"
[2]: https://dl.acm.org/doi/10.1007/s00145-019-09319-x "Fast Fully Homomorphic Encryption Over the Torus"
[3]: https://arxiv.org/pdf/2202.02960.pdf "Comprehensive Performance Analysis of
Homomorphic Cryptosystems for Practical Data Processing"
[4]: https://understandingpatientdata.org.uk/ "Understanding Patient Data"
[5]: https://www.jstor.org/stable/2283137 "Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias"
[6]: https://s2geometry.io/about/overview "S2 Geometry"

